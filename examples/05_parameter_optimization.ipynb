{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Parameter Optimization\n\nFind optimal strategy parameters through grid search, walk-forward analysis, and out-of-sample validation."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from clyptq import CostModel, Constraints\n",
    "from clyptq.data.loaders.ccxt import load_crypto_data\n",
    "from clyptq.trading.execution import BacktestExecutor\n",
    "from clyptq.trading.factors.library.momentum import MomentumFactor\n",
    "from clyptq.trading.factors.library.volatility import VolatilityFactor\n",
    "from clyptq.trading.portfolio.constructors import TopNConstructor\n",
    "from clyptq.trading.strategy.base import SimpleStrategy\n",
    "from clyptq.trading.optimization import GridSearchOptimizer, WalkForwardOptimizer\n",
    "from clyptq.trading.optimization.validation import HistoricalSimulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization period: 2025-01-04 to 2026-01-04\n"
     ]
    }
   ],
   "source": [
    "symbols = [\n",
    "    \"BTC/USDT\", \"ETH/USDT\", \"BNB/USDT\", \"SOL/USDT\", \"XRP/USDT\",\n",
    "    \"ADA/USDT\", \"AVAX/USDT\", \"DOGE/USDT\", \"DOT/USDT\", \"MATIC/USDT\",\n",
    "]\n",
    "\n",
    "store = load_crypto_data(symbols=symbols, exchange=\"binance\", timeframe=\"1d\", days=720)\n",
    "date_range = store.get_date_range()\n",
    "start = date_range.end - timedelta(days=365)\n",
    "end = date_range.end\n",
    "\n",
    "print(f\"Optimization period: {start.date()} to {end.date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Parameterized Strategy\n",
    "\n",
    "Momentum strategy with tunable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class MomentumStrategy(SimpleStrategy):\n    def __init__(self, lookback=30, top_n=3):\n        self.lookback = lookback\n        self.top_n = top_n\n        \n        factors = [\n            MomentumFactor(lookback=lookback),\n            VolatilityFactor(lookback=lookback),\n        ]\n        constraints = Constraints(\n            max_position_size=0.40,\n            max_gross_exposure=1.0,\n            min_position_size=0.10,\n            max_num_positions=5,\n        )\n        super().__init__(\n            factors_list=factors,\n            constructor=TopNConstructor(top_n=top_n),\n            constraints_obj=constraints,\n            schedule_str=\"weekly\",\n            warmup=lookback + 5,\n            name=f\"Momentum-{lookback}-{top_n}\",\n        )\n\ndef strategy_factory(params):\n    \"\"\"Factory function that creates strategy from params dict.\"\"\"\n    return MomentumStrategy(lookback=params.get(\"lookback\", 30), top_n=params.get(\"top_n\", 3))\n\nprint(\"Strategy template: Momentum(lookback, top_n)\")\nprint(\"Parameters to optimize: lookback [10, 20, 30, 40], top_n [2, 3, 4, 5]\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Grid Search\n",
    "\n",
    "Test all parameter combinations, find best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "param_grid = {\n    \"lookback\": [10, 20, 30, 40],\n    \"top_n\": [2, 3, 4, 5],\n}\n\ncost_model = CostModel(maker_fee=0.001, taker_fee=0.001, slippage_bps=5.0)\nexecutor = BacktestExecutor(cost_model)\n\noptimizer = GridSearchOptimizer(\n    strategy_factory=strategy_factory,\n    data_store=store,\n    executor=executor,\n    initial_capital=100000.0,\n    scoring_metric=\"sharpe_ratio\",\n)\n\nprint(f\"Testing {len(param_grid['lookback']) * len(param_grid['top_n'])} configurations...\")\ngrid_result = optimizer.search(\n    param_grid=param_grid,\n    start=start,\n    end=end,\n    cv_folds=3,\n)\n\nprint(\"\\nGRID SEARCH RESULTS\")\nprint(\"=\" * 80)\nprint(f\"Best parameters: {grid_result.best_params}\")\nprint(f\"Best Sharpe: {grid_result.best_score:.3f}\")\nprint(f\"Total combinations tested: {len(grid_result.all_results)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 10 CONFIGURATIONS\n",
      "================================================================================\n",
      "Rank   Lookback   Top N    Sharpe    \n",
      "================================================================================\n",
      "1      10         5         155.088\n",
      "2      10         3          68.982\n",
      "3      10         4          40.657\n",
      "4      20         2           0.000\n",
      "5      20         3           0.000\n",
      "6      20         4           0.000\n",
      "7      20         5           0.000\n",
      "8      30         2           0.000\n",
      "9      30         3           0.000\n",
      "10     30         4           0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTOP 10 CONFIGURATIONS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<6} {'Lookback':<10} {'Top N':<8} {'Sharpe':<10}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "top_configs = sorted(\n",
    "    grid_result.all_results,\n",
    "    key=lambda x: x[\"score\"],\n",
    "    reverse=True\n",
    ")[:10]\n",
    "\n",
    "for i, config in enumerate(top_configs, 1):\n",
    "    print(\n",
    "        f\"{i:<6} \"\n",
    "        f\"{config['params']['lookback']:<10} \"\n",
    "        f\"{config['params']['top_n']:<8} \"\n",
    "        f\"{config['score']:>8.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Walk-Forward Analysis\n\nValidate parameters on rolling windows: train on 60 days, test on next 30 days, repeat."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "wf_optimizer = WalkForwardOptimizer(\n    strategy_factory=lambda **params: MomentumStrategy(**params),\n    param_grid=param_grid,\n    train_days=60,\n    test_days=30,\n    metric=\"sharpe_ratio\",\n    initial_capital=100000.0,\n)\n\nprint(\"Running walk-forward (train 60d, test 30d)...\")\nwf_result = wf_optimizer.optimize(\n    data_store=store,\n    start=start,\n    end=end,\n    verbose=True,\n)\n\nprint(\"\\nWALK-FORWARD RESULTS\")\nprint(\"=\" * 80)\nprint(f\"Number of windows: {len(wf_result.windows)}\")\nprint(f\"Mean train Sharpe: {wf_result.avg_train_metric:.3f}\")\nprint(f\"Mean test Sharpe: {wf_result.avg_test_metric:.3f}\")\n\n# Calculate degradation manually\nif wf_result.avg_train_metric > 0:\n    degradation = (wf_result.avg_train_metric - wf_result.avg_test_metric) / wf_result.avg_train_metric\n    print(f\"Degradation: {degradation:.2%}\")\n\n# Show most frequent parameter combinations\nprint(\"\\nMost frequent parameter combinations:\")\nfor params_str, count in sorted(wf_result.best_params_frequency.items(), key=lambda x: x[1], reverse=True)[:3]:\n    print(f\"  {params_str}: {count} windows\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Out-of-Sample Validation\n\nTest on unseen data to detect overfitting."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Split data: train (first 6 months), test (last 6 months)\nmid_date = start + timedelta(days=180)\n\nsimulator = HistoricalSimulator(\n    strategy_factory=strategy_factory,\n    data_store=store,\n    executor=executor,\n    initial_capital=100000.0,\n    overfitting_threshold=0.3,\n)\n\nprint(f\"Train: {start.date()} to {mid_date.date()}\")\nprint(f\"Test:  {mid_date.date()} to {end.date()}\")\n\noos_result = simulator.run_out_of_sample(\n    train_start=start,\n    train_end=mid_date,\n    test_start=mid_date + timedelta(days=1),\n    test_end=end,\n    params=grid_result.best_params,\n)\n\nprint(\"\\nOUT-OF-SAMPLE VALIDATION\")\nprint(\"=\" * 80)\nprint(f\"Train Sharpe:       {oos_result.train_result.metrics.sharpe_ratio:>8.3f}\")\nprint(f\"Test Sharpe:        {oos_result.test_result.metrics.sharpe_ratio:>8.3f}\")\nprint(f\"Degradation:        {oos_result.degradation_ratio:>8.2%}\")\nprint(f\"Stability Score:    {oos_result.stability_score:>8.2%}\")\nprint(f\"Overfitted:         {oos_result.is_overfitted}\")\n\nif oos_result.is_overfitted:\n    print(\"\\nWARNING: Strategy may be overfitted to training data\")\nelse:\n    print(\"\\nParameters validated: stable out-of-sample performance\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Parameter Stability Analysis\n\nTest if nearby parameters also work to avoid parameter overfitting."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test parameters around best\nbest_lookback = grid_result.best_params[\"lookback\"]\ntest_grid = [\n    {\"lookback\": best_lookback - 10, \"top_n\": grid_result.best_params[\"top_n\"]},\n    {\"lookback\": best_lookback, \"top_n\": grid_result.best_params[\"top_n\"]},\n    {\"lookback\": best_lookback + 10, \"top_n\": grid_result.best_params[\"top_n\"]},\n]\n\nps_result = simulator.analyze_parameter_stability(\n    param_grid=test_grid,\n    train_start=start,\n    train_end=mid_date,\n    test_start=mid_date + timedelta(days=1),\n    test_end=end,\n)\n\nprint(\"\\nPARAMETER STABILITY\")\nprint(\"=\" * 80)\nprint(f\"Tested {len(test_grid)} nearby configurations\")\nprint(f\"Robust configs: {len(ps_result.robust_params)}\")\nprint(\"\\nStability scores:\")\nfor config_key, score in sorted(ps_result.stability_scores.items(), key=lambda x: x[1], reverse=True):\n    config_idx = int(config_key.split(\"_\")[1])\n    params = test_grid[config_idx]\n    print(f\"  Lookback {params['lookback']}: {score:.2%}\")\n\nif len(ps_result.robust_params) >= 2:\n    print(\"\\nParameters are stable (nearby values also work)\")\nelse:\n    print(\"\\nParameters may be fragile (only one config works well)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "**Grid Search**:\n",
    "- Found best parameters\n",
    "- Cross-validation prevents overfitting\n",
    "\n",
    "**Walk-Forward**:\n",
    "- Validates on rolling windows\n",
    "- Tests parameter robustness over time\n",
    "\n",
    "**Out-of-Sample**:\n",
    "- Critical final validation\n",
    "- Degradation <30% is acceptable\n",
    "\n",
    "**Stability**:\n",
    "- Nearby parameters should also work\n",
    "- Fragile parameters = overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **06_portfolio_optimization.ipynb**: Optimize portfolio construction\n",
    "- **07_risk_analysis.ipynb**: Comprehensive risk testing\n",
    "- **08_paper_trading.ipynb**: Deploy to paper trading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
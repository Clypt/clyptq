{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClyptQ Operators & Transforms\n",
    "\n",
    "Testing various features of the operator module:\n",
    "1. Time-series operators (ts_*)\n",
    "2. Cross-sectional operators (rank, demean, etc.)\n",
    "3. Cross-alpha operators (ca_*)\n",
    "4. Arithmetic operators\n",
    "5. Transform pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from clyptq import operator\n",
    "from clyptq.data.provider import DataProvider\n",
    "from clyptq.data.spec import OHLCVSpec\n",
    "from clyptq.universe import CryptoLiquid\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data\n",
    "ohlcv_spec = OHLCVSpec(exchange=\"gateio\", market_type=\"spot\", timeframe=\"1d\")\n",
    "universe = CryptoLiquid(top_n=30, min_dollar_volume=100_000)\n",
    "\n",
    "p = DataProvider(\n",
    "    universe=universe,\n",
    "    specs={\"ohlcv\": ohlcv_spec},\n",
    "    rebalance_freq=\"1d\",\n",
    "    mode=\"research\",\n",
    ")\n",
    "p.load(start=datetime(2025, 10, 15), end=datetime(2026, 1, 5))\n",
    "\n",
    "close = p[\"close\"]\n",
    "volume = p[\"volume\"]\n",
    "high = p[\"high\"]\n",
    "low = p[\"low\"]\n",
    "\n",
    "print(f\"Data shape: {close.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time-Series Operators (ts_*)\n",
    "\n",
    "Time-axis operations (rolling window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=== Time-Series Operators ===\")\n",
    "\n",
    "# Rolling statistics\n",
    "ts_mean_20 = operator.ts_mean(close, 20)\n",
    "ts_std_20 = operator.ts_std(close, 20)\n",
    "ts_min_20 = operator.ts_min(close, 20)\n",
    "ts_max_20 = operator.ts_max(close, 20)\n",
    "ts_sum_20 = operator.ts_sum(volume, 20)\n",
    "\n",
    "print(f\"ts_mean(20): {ts_mean_20.shape}\")\n",
    "print(f\"ts_std(20): {ts_std_20.shape}\")\n",
    "print(f\"ts_min(20): {ts_min_20.shape}\")\n",
    "print(f\"ts_max(20): {ts_max_20.shape}\")\n",
    "print(f\"ts_sum(20): {ts_sum_20.shape}\")\n",
    "\n",
    "# Returns\n",
    "returns_1d = operator.ts_returns(close, period=1)\n",
    "returns_5d = operator.ts_returns(close, period=5)\n",
    "returns_20d = operator.ts_returns(close, period=20)\n",
    "\n",
    "print(f\"\\nts_returns(1): {returns_1d.shape}\")\n",
    "print(f\"ts_returns(5): {returns_5d.shape}\")\n",
    "print(f\"ts_returns(20): {returns_20d.shape}\")\n",
    "\n",
    "# Lag/Delay\n",
    "lagged_1 = operator.ts_delay(close, 1)\n",
    "lagged_5 = operator.ts_delay(close, 5)\n",
    "\n",
    "print(f\"\\nts_delay(1): {lagged_1.shape}\")\n",
    "print(f\"ts_delay(5): {lagged_5.shape}\")\n",
    "\n",
    "# Delta\n",
    "delta_1 = operator.ts_delta(close, 1)\n",
    "delta_5 = operator.ts_delta(close, 5)\n",
    "\n",
    "print(f\"\\nts_delta(1): {delta_1.shape}\")\n",
    "print(f\"ts_delta(5): {delta_5.shape}\")\n",
    "\n",
    "# Rank within rolling window\n",
    "ts_rank_20 = operator.ts_rank(close, 20)\n",
    "print(f\"\\nts_rank(20): {ts_rank_20.shape}, range: [{ts_rank_20.min().min():.2f}, {ts_rank_20.max().max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Rolling correlation & covariance\n",
    "print(\"=== Rolling Correlation/Covariance ===\")\n",
    "\n",
    "ts_corr = operator.ts_corr(close, volume, window=20)\n",
    "ts_cov = operator.ts_cov(close, volume, window=20)\n",
    "\n",
    "print(f\"ts_corr(close, volume, 20): {ts_corr.shape}\")\n",
    "print(f\"ts_cov(close, volume, 20): {ts_cov.shape}\")\n",
    "\n",
    "# Sample values\n",
    "print(f\"\\nCorrelation sample (last row, first 5 symbols):\")\n",
    "print(ts_corr.iloc[-1].dropna().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-Sectional Operators\n",
    "\n",
    "Operations across symbols at each timestamp (row-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=== Cross-Sectional Operators ===\")\n",
    "\n",
    "# Rank: symbol ranking at each timestamp (0~1)\n",
    "ranked = operator.rank(returns_20d)\n",
    "print(f\"rank: shape={ranked.shape}, range=[{ranked.min().min():.2f}, {ranked.max().max():.2f}]\")\n",
    "\n",
    "# Demean: remove mean at each timestamp\n",
    "demeaned = operator.demean(ranked)\n",
    "print(f\"demean: row_mean={demeaned.iloc[-1].mean():.10f} (should be ~0)\")\n",
    "\n",
    "# Z-score normalization\n",
    "zscored = operator.zscore(returns_20d)\n",
    "print(f\"zscore: row_mean={zscored.iloc[-1].mean():.6f}, row_std={zscored.iloc[-1].std():.6f}\")\n",
    "\n",
    "# L1 norm: sum of |weights| = 1\n",
    "l1_normed = operator.l1_norm(ranked)\n",
    "print(f\"l1_norm: sum={l1_normed.iloc[-1].sum():.6f} (should be 1)\")\n",
    "\n",
    "# L2 norm: sum of weights^2 = 1\n",
    "l2_normed = operator.l2_norm(ranked)\n",
    "print(f\"l2_norm: sum_sq={(l2_normed.iloc[-1]**2).sum():.6f} (should be 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Winsorize: cap extreme values (mean ± std_mult * std)\n",
    "print(\"\\n=== Winsorize ===\")\n",
    "\n",
    "# std_mult=3: cap at mean ± 3*std\n",
    "winsorized = operator.winsorize(returns_20d, std_mult=3)\n",
    "print(f\"Original range: [{returns_20d.min().min():.4f}, {returns_20d.max().max():.4f}]\")\n",
    "print(f\"Winsorized range (3 std): [{winsorized.min().min():.4f}, {winsorized.max().max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clip: limit value range\n",
    "print(\"\\n=== Clip ===\")\n",
    "\n",
    "signal = operator.demean(operator.rank(returns_20d))\n",
    "clipped = operator.clip(signal, lower=-0.1, upper=0.1)\n",
    "\n",
    "print(f\"Original range: [{signal.min().min():.4f}, {signal.max().max():.4f}]\")\n",
    "print(f\"Clipped range: [{clipped.min().min():.4f}, {clipped.max().max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Alpha Operators (ca_*)\n",
    "\n",
    "Combining multiple alpha signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=== Cross-Alpha Operators ===\")\n",
    "\n",
    "# Create multiple alphas\n",
    "alpha1 = operator.rank(operator.ts_returns(close, period=5))\n",
    "alpha2 = operator.rank(operator.ts_returns(close, period=10))\n",
    "alpha3 = operator.rank(operator.ts_returns(close, period=20))\n",
    "\n",
    "print(f\"Alpha1 (5d momentum): {alpha1.shape}\")\n",
    "print(f\"Alpha2 (10d momentum): {alpha2.shape}\")\n",
    "print(f\"Alpha3 (20d momentum): {alpha3.shape}\")\n",
    "\n",
    "# Average\n",
    "avg = operator.ca_reduce_avg(alpha1, alpha2, alpha3)\n",
    "print(f\"\\nca_reduce_avg: {avg.shape}\")\n",
    "\n",
    "# Sum\n",
    "summed = operator.ca_reduce_sum(alpha1, alpha2, alpha3)\n",
    "print(f\"ca_reduce_sum: {summed.shape}\")\n",
    "\n",
    "# Max/Min\n",
    "maxed = operator.ca_reduce_max(alpha1, alpha2, alpha3)\n",
    "mined = operator.ca_reduce_min(alpha1, alpha2, alpha3)\n",
    "print(f\"ca_reduce_max: {maxed.shape}\")\n",
    "print(f\"ca_reduce_min: {mined.shape}\")\n",
    "\n",
    "# Weighted average\n",
    "weights = [0.5, 0.3, 0.2]\n",
    "weighted = operator.ca_weighted_sum(alpha1, alpha2, alpha3, weights=weights)\n",
    "print(f\"\\nca_weighted_sum (w={weights}): {weighted.shape}\")\n",
    "\n",
    "# Standard deviation (alpha disagreement)\n",
    "std = operator.ca_reduce_stddev(alpha1, alpha2, alpha3)\n",
    "print(f\"ca_reduce_stddev: {std.shape}\")\n",
    "\n",
    "# Median (robust to outliers)\n",
    "median = operator.ca_reduce_median(alpha1, alpha2, alpha3)\n",
    "print(f\"ca_reduce_median: {median.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Arithmetic Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=== Arithmetic Operators ===\")\n",
    "\n",
    "# Basic arithmetic\n",
    "a = operator.add(close, 100)\n",
    "b = operator.sub(close, high)\n",
    "c = operator.mul(close, volume)  # Dollar volume\n",
    "d = operator.div(close, operator.add(volume, 1e-8))\n",
    "\n",
    "print(f\"add(close, 100): {a.shape}\")\n",
    "print(f\"sub(close, high): {b.shape}\")\n",
    "print(f\"mul(close, volume): {c.shape}\")\n",
    "print(f\"div(close, volume): {d.shape}\")\n",
    "\n",
    "# Unary operations\n",
    "negated = operator.neg(returns_20d)\n",
    "absoluted = operator.abs(returns_20d)\n",
    "signed = operator.sign(returns_20d)\n",
    "\n",
    "print(f\"\\nneg: {negated.shape}\")\n",
    "print(f\"abs: {absoluted.shape}\")\n",
    "print(f\"sign: unique values = {signed.iloc[-1].dropna().unique()}\")\n",
    "\n",
    "# Math functions\n",
    "logged = operator.log(operator.add(close, 1))  # log(1+x)\n",
    "sqrted = operator.sqrt(operator.abs(returns_20d))\n",
    "powered = operator.pow(returns_20d, 2)\n",
    "\n",
    "print(f\"\\nlog(1+close): {logged.shape}\")\n",
    "print(f\"sqrt(|returns|): {sqrted.shape}\")\n",
    "print(f\"pow(returns, 2): {powered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison & Logical Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=== Comparison Operators ===\")\n",
    "\n",
    "# Comparison\n",
    "gt_ma = operator.gt(close, ts_mean_20)  # close > MA20\n",
    "lt_ma = operator.lt(close, ts_mean_20)  # close < MA20\n",
    "\n",
    "print(f\"gt(close, MA20): {gt_ma.sum().sum()} True values\")\n",
    "print(f\"lt(close, MA20): {lt_ma.sum().sum()} True values\")\n",
    "\n",
    "# Logical\n",
    "both = operator.logical_and(gt_ma, operator.gt(volume, operator.ts_mean(volume, 20)))\n",
    "either = operator.logical_or(gt_ma, lt_ma)\n",
    "\n",
    "print(f\"\\nlogical_and: {both.sum().sum()} True values\")\n",
    "print(f\"logical_or: {either.sum().sum()} True values\")\n",
    "\n",
    "# Where (conditional)\n",
    "# If returns positive, keep; if negative, set to 0\n",
    "positive_only = operator.where(operator.gt(returns_20d, 0), returns_20d, 0)\n",
    "print(f\"\\nwhere(returns > 0, returns, 0): min={positive_only.min().min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Missing Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=== Missing Data ===\")\n",
    "\n",
    "# Check NaN\n",
    "is_na = operator.isna(returns_20d)\n",
    "not_na = operator.notna(returns_20d)\n",
    "\n",
    "print(f\"isna: {is_na.sum().sum()} NaN values\")\n",
    "print(f\"notna: {not_na.sum().sum()} non-NaN values\")\n",
    "\n",
    "# Fill NaN\n",
    "filled_zero = operator.fillna(returns_20d, 0)\n",
    "print(f\"\\nfillna(0): {filled_zero.isna().sum().sum()} NaN remaining\")\n",
    "\n",
    "# Forward fill\n",
    "ffilled = operator.ffill(returns_20d)\n",
    "print(f\"ffill: {ffilled.isna().sum().sum()} NaN remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transform Pipeline Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=== Transform Pipeline ===\")\n",
    "\n",
    "# Momentum signal generation pipeline\n",
    "def momentum_signal(close, period=20):\n",
    "    \"\"\"Momentum signal pipeline.\"\"\"\n",
    "    # 1. Calculate returns\n",
    "    returns = operator.ts_returns(close, period=period)\n",
    "    \n",
    "    # 2. Winsorize (remove outliers) - mean ± 3*std\n",
    "    returns = operator.winsorize(returns, std_mult=3)\n",
    "    \n",
    "    # 3. Rank (0~1)\n",
    "    ranked = operator.rank(returns)\n",
    "    \n",
    "    # 4. Demean (long/short)\n",
    "    demeaned = operator.demean(ranked)\n",
    "    \n",
    "    # 5. L1 normalize\n",
    "    normalized = operator.l1_norm(demeaned)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "signal = momentum_signal(close, period=20)\n",
    "\n",
    "print(f\"Pipeline output:\")\n",
    "print(f\"  - Shape: {signal.shape}\")\n",
    "print(f\"  - Row sum (should be 0): {signal.iloc[-1].sum():.10f}\")\n",
    "print(f\"  - Abs row sum (should be 1): {signal.iloc[-1].abs().sum():.6f}\")\n",
    "print(f\"  - Range: [{signal.min().min():.4f}, {signal.max().max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Timeframe Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=== Multi-Timeframe ===\")\n",
    "\n",
    "# 1d, 3d, 5d data (auto ffill)\n",
    "close_1d = p[\"close\"]\n",
    "close_3d = p[\"close\", \"3d\"]\n",
    "close_5d = p[\"close\", \"5d\"]\n",
    "\n",
    "print(f\"1d shape: {close_1d.shape}\")\n",
    "print(f\"3d shape: {close_3d.shape} (auto-aligned to 1d)\")\n",
    "print(f\"5d shape: {close_5d.shape} (auto-aligned to 1d)\")\n",
    "\n",
    "# Calculate momentum for each timeframe\n",
    "alpha_1d = operator.rank(operator.ts_returns(close_1d, period=5))\n",
    "alpha_3d = operator.rank(operator.ts_returns(close_3d, period=3))\n",
    "alpha_5d = operator.rank(operator.ts_returns(close_5d, period=5))\n",
    "\n",
    "# Combine\n",
    "combined = operator.ca_weighted_sum(\n",
    "    alpha_1d, alpha_3d, alpha_5d,\n",
    "    weights=[0.5, 0.3, 0.2]\n",
    ")\n",
    "\n",
    "# Normalize\n",
    "final = operator.l1_norm(operator.demean(combined))\n",
    "\n",
    "print(f\"\\nCombined signal:\")\n",
    "print(f\"  - Shape: {final.shape}\")\n",
    "print(f\"  - Abs sum: {final.iloc[-1].abs().sum():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Operator Categories\n",
    "\n",
    "| Category | Examples | Description |\n",
    "|----------|----------|-------------|\n",
    "| Time-series (ts_*) | ts_mean, ts_std, ts_returns, ts_delay | Time-axis rolling operations |\n",
    "| Cross-sectional | rank, demean, zscore, l1_norm | Operations across symbols |\n",
    "| Cross-alpha (ca_*) | ca_reduce_avg, ca_weighted_sum | Alpha combination |\n",
    "| Arithmetic | add, sub, mul, div, neg, abs | Basic operations |\n",
    "| Comparison | gt, lt, eq, where | Comparison/conditional |\n",
    "| Missing | fillna, ffill, isna | Missing data handling |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Operators & Transforms test complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

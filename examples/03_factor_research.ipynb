{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Factor Research\n\nDevelop and validate alpha factors through IC analysis, IC decay testing, turnover-performance tradeoffs, and factor orthogonalization."
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from clyptq import CostModel, Constraints\n",
    "from clyptq.analytics.factors import FactorAnalyzer\n",
    "from clyptq.data.loaders.ccxt import load_crypto_data\n",
    "from clyptq.trading.execution import BacktestExecutor\n",
    "from clyptq.trading.factors.library.momentum import MomentumFactor\n",
    "from clyptq.trading.factors.library.volatility import VolatilityFactor\n",
    "from clyptq.trading.factors.library.volume import VolumeFactor\n",
    "from clyptq.trading.factors.library.mean_reversion import BollingerFactor\n",
    "from clyptq.trading.factors.library.liquidity import AmihudFactor\n",
    "from clyptq.trading.factors.ops.factor_combination import orthogonalize_factors, pca_factors\n",
    "from clyptq.trading.portfolio.constructors import ScoreWeightedConstructor\n",
    "from clyptq.trading.strategy.base import SimpleStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data returned for symbol\n",
      "No data for symbol\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research period: 2025-09-06 to 2026-01-04\n"
     ]
    }
   ],
   "source": [
    "symbols = [\n",
    "    \"BTC/USDT\", \"ETH/USDT\", \"BNB/USDT\", \"SOL/USDT\", \"XRP/USDT\",\n",
    "    \"ADA/USDT\", \"AVAX/USDT\", \"DOGE/USDT\", \"DOT/USDT\", \"MATIC/USDT\",\n",
    "]\n",
    "\n",
    "store = load_crypto_data(symbols=symbols, exchange=\"binance\", timeframe=\"1d\", days=180)\n",
    "date_range = store.get_date_range()\n",
    "start = date_range.end - timedelta(days=120)\n",
    "end = date_range.end\n",
    "\n",
    "print(f\"Research period: {start.date()} to {end.date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Factors\n",
    "\n",
    "5 factors: Momentum, Mean Reversion, Volatility, Volume, Liquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 5 factors:\n",
      "  1. MomentumFactor (lookback=30)\n",
      "  2. BollingerFactor (lookback=20)\n",
      "  3. VolatilityFactor (lookback=30)\n",
      "  4. VolumeFactor (lookback=30)\n",
      "  5. AmihudFactor (lookback=20)\n"
     ]
    }
   ],
   "source": [
    "factors = [\n",
    "    MomentumFactor(lookback=30),\n",
    "    BollingerFactor(lookback=20, num_std=2.0),\n",
    "    VolatilityFactor(lookback=30),\n",
    "    VolumeFactor(lookback=30),\n",
    "    AmihudFactor(lookback=20),\n",
    "]\n",
    "\n",
    "print(f\"Testing {len(factors)} factors:\")\n",
    "for i, factor in enumerate(factors, 1):\n",
    "    lookback = getattr(factor, 'lookback', 'N/A')\n",
    "    print(f\"  {i}. {factor.__class__.__name__} (lookback={lookback})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Factor Correlation Matrix\n",
    "\n",
    "Check if factors are independent or redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACTOR CORRELATION MATRIX\n",
      "================================================================================\n",
      "                  MomentumFactor  BollingerFactor  VolatilityFactor  \\\n",
      "MomentumFactor             1.000           -0.759             0.153   \n",
      "BollingerFactor           -0.759            1.000            -0.126   \n",
      "VolatilityFactor           0.153           -0.126             1.000   \n",
      "VolumeFactor               0.159           -0.188            -0.632   \n",
      "AmihudFactor               0.163           -0.027             0.761   \n",
      "\n",
      "                  VolumeFactor  AmihudFactor  \n",
      "MomentumFactor           0.159         0.163  \n",
      "BollingerFactor         -0.188        -0.027  \n",
      "VolatilityFactor        -0.632         0.761  \n",
      "VolumeFactor             1.000        -0.357  \n",
      "AmihudFactor            -0.357         1.000  \n",
      "\n",
      "Interpretation:\n",
      "  |corr| < 0.3: Independent (good for diversification)\n",
      "  |corr| > 0.7: Redundant (consider removing one)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compute factor scores at latest timestamp\n",
    "latest_date = date_range.end - timedelta(days=1)\n",
    "view = store.get_view(latest_date)\n",
    "\n",
    "factor_scores = {}\n",
    "for factor in factors:\n",
    "    scores = factor.compute(view)\n",
    "    factor_scores[factor.__class__.__name__] = scores\n",
    "\n",
    "# Get all symbols\n",
    "all_symbols = sorted(set().union(*[set(scores.keys()) for scores in factor_scores.values()]))\n",
    "\n",
    "# Create score matrix\n",
    "score_matrix = {}\n",
    "for factor_name, scores in factor_scores.items():\n",
    "    score_matrix[factor_name] = [scores.get(symbol, np.nan) for symbol in all_symbols]\n",
    "\n",
    "# Compute correlation\n",
    "df = pd.DataFrame(score_matrix)\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "print(\"FACTOR CORRELATION MATRIX\")\n",
    "print(\"=\" * 80)\n",
    "print(corr_matrix.round(3))\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  |corr| < 0.3: Independent (good for diversification)\")\n",
    "print(\"  |corr| > 0.7: Redundant (consider removing one)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. IC Decay Analysis\n",
    "\n",
    "**Question**: How long does factor signal last?\n",
    "\n",
    "- Fast decay → rebalance frequently\n",
    "- Slow decay → hold longer, lower turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IC DECAY ANALYSIS (First 3 factors)\n",
      "\n",
      "1. MomentumFactor\n",
      "================================================================================\n",
      "Horizon    Mean IC      Abs IC      \n",
      "----------------------------------------\n",
      "Day 1         0.0293      0.3666\n",
      "Day 2         0.0341      0.3691\n",
      "Day 3         0.0573      0.3683\n",
      "Day 4         0.0653      0.3626\n",
      "Day 5         0.0617      0.3436\n",
      "\n",
      "Half-life: ~>10 days\n",
      "\n",
      "2. BollingerFactor\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaden/Desktop/clypt-llm/clypt-trading-engine/venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:3023: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/jaden/Desktop/clypt-llm/clypt-trading-engine/venv/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:3024: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon    Mean IC      Abs IC      \n",
      "----------------------------------------\n",
      "Day 1            nan         nan\n",
      "Day 2            nan         nan\n",
      "Day 3            nan         nan\n",
      "Day 4            nan         nan\n",
      "Day 5            nan         nan\n",
      "\n",
      "3. VolatilityFactor\n",
      "================================================================================\n",
      "Horizon    Mean IC      Abs IC      \n",
      "----------------------------------------\n",
      "Day 1         0.1302      0.4505\n",
      "Day 2         0.1442      0.4465\n",
      "Day 3         0.1847      0.4452\n",
      "Day 4         0.1944      0.4336\n",
      "Day 5         0.2107      0.4325\n",
      "\n",
      "Half-life: ~>10 days\n"
     ]
    }
   ],
   "source": [
    "analyzer = FactorAnalyzer()\n",
    "\n",
    "print(\"\\nIC DECAY ANALYSIS (First 3 factors)\")\n",
    "\n",
    "for i, factor in enumerate(factors[:3], 1):\n",
    "    print(f\"\\n{i}. {factor.__class__.__name__}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    decay_df = analyzer.ic_decay_analysis(factor=factor, data=store, max_horizon=10)\n",
    "    \n",
    "    if not decay_df.empty:\n",
    "        print(f\"{'Horizon':<10} {'Mean IC':<12} {'Abs IC':<12}\")\n",
    "        print(\"-\" * 40)\n",
    "        for _, row in decay_df.head(5).iterrows():\n",
    "            print(f\"Day {int(row['horizon']):<5} {row['mean_ic']:>10.4f}  {row['abs_mean_ic']:>10.4f}\")\n",
    "        \n",
    "        # Find half-life (where IC drops to 50%)\n",
    "        initial_ic = abs(decay_df.iloc[0]['mean_ic'])\n",
    "        if initial_ic > 0.01:\n",
    "            half_ic = initial_ic * 0.5\n",
    "            half_life_idx = (decay_df['abs_mean_ic'] < half_ic).idxmax() if (decay_df['abs_mean_ic'] < half_ic).any() else len(decay_df)\n",
    "            print(f\"\\nHalf-life: ~{int(decay_df.iloc[half_life_idx]['horizon']) if half_life_idx < len(decay_df) else '>10'} days\")\n",
    "    else:\n",
    "        print(\"Not enough data for decay analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Turnover-Performance Tradeoff\n",
    "\n",
    "**Goal**: Find optimal rebalancing frequency\n",
    "\n",
    "- Daily: High costs, captures fast signals\n",
    "- Weekly: Balanced\n",
    "- Monthly: Low costs, misses opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from clyptq.trading.engine import BacktestEngine\n\nclass TestStrategy(SimpleStrategy):\n    def __init__(self, schedule=\"weekly\"):\n        super().__init__(\n            factors_list=factors,\n            constructor=ScoreWeightedConstructor(use_long_short=False),\n            constraints_obj=Constraints(\n                max_position_size=0.25,\n                max_gross_exposure=0.95,\n                min_position_size=0.10,\n                max_num_positions=5,\n            ),\n            schedule_str=schedule,\n            warmup=35,\n            name=f\"Test-{schedule}\",\n        )\n\ncost_model = CostModel(maker_fee=0.001, taker_fee=0.001, slippage_bps=5.0)\nexecutor = BacktestExecutor(cost_model)\n\n# Test different rebalancing frequencies\nfrequencies = [\"daily\", \"weekly\", \"monthly\"]\nresults = {}\n\nprint(\"Testing rebalance frequencies...\")\nfor freq in frequencies:\n    print(f\"  {freq}...\")\n    strategy = TestStrategy(schedule=freq)\n    engine = BacktestEngine(strategy, store, executor, 100000.0)\n    result = engine.run(start=start, end=end, verbose=False)\n    \n    # Calculate turnover (total traded value / average portfolio value)\n    total_traded = sum(abs(f.amount * f.price) for f in result.trades)\n    avg_equity = sum(s.equity for s in result.snapshots) / len(result.snapshots) if result.snapshots else 1.0\n    turnover = total_traded / avg_equity if avg_equity > 0 else 0.0\n    \n    results[freq] = {\n        \"total_return\": result.metrics.total_return,\n        \"sharpe_ratio\": result.metrics.sharpe_ratio,\n        \"turnover\": turnover,\n        \"num_trades\": len(result.trades),\n    }\n\nprint(\"\\nTURNOVER-PERFORMANCE FRONTIER\")\nprint(\"=\" * 90)\nprint(f\"{'Frequency':<15} {'Return':<12} {'Sharpe':<10} {'Turnover':<12} {'Trades':<10}\")\nprint(\"=\" * 90)\n\nfor freq, metrics in results.items():\n    print(\n        f\"{freq:<15} \"\n        f\"{metrics['total_return']:>10.2%}  \"\n        f\"{metrics['sharpe_ratio']:>8.3f}  \"\n        f\"{metrics['turnover']:>10.1%}  \"\n        f\"{metrics['num_trades']:>8}\"\n    )\n\n# Find optimal frequency (best Sharpe ratio)\noptimal_freq = max(results.items(), key=lambda x: x[1][\"sharpe_ratio\"])[0]\nprint(f\"\\nOptimal frequency: {optimal_freq}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Factor Orthogonalization\n",
    "\n",
    "**Problem**: Factors may be correlated (redundant)\n",
    "\n",
    "**Solution**: Orthogonalize to remove overlap\n",
    "\n",
    "**Benefits**:\n",
    "- Independent factors\n",
    "- Better diversification\n",
    "- Reduced multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get factor scores at latest date\nview = store.get_view(end - timedelta(days=1))\nraw_scores = {}\nfor factor in factors:\n    scores = factor.compute(view)\n    raw_scores[factor.__class__.__name__] = scores\n\nprint(f\"Computing {len(raw_scores)} factor scores...\")\nprint(f\"Universe size: {len(next(iter(raw_scores.values())))} symbols\")\n\n# Orthogonalize\northogonal_scores = orthogonalize_factors(raw_scores)\nprint(f\"\\nOrthogonalized {len(orthogonal_scores)} factors\")\nprint(\"Result: Independent factors with zero correlation\")\n\n# PCA reduction\nn_components = 3\npca_scores = pca_factors(raw_scores, n_components=n_components)\nprint(f\"\\nPCA: {len(raw_scores)} factors -> {n_components} principal components\")\nprint(f\"PC names: {list(pca_scores.keys())}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Research Workflow Summary\n",
    "\n",
    "**Step 1**: Correlation Analysis\n",
    "- Check factor independence\n",
    "- Remove highly correlated factors (|corr| >0.7)\n",
    "\n",
    "**Step 2**: IC Decay\n",
    "- Fast decay → rebalance frequently\n",
    "- Slow decay → hold longer\n",
    "\n",
    "**Step 3**: Turnover Analysis\n",
    "- Find sweet spot between signal capture and costs\n",
    "\n",
    "**Step 4**: Orthogonalization\n",
    "- Remove redundancy\n",
    "- Use PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **04_strategy_comparison.ipynb**: Build strategies with your factors\n",
    "- **05_parameter_optimization.ipynb**: Optimize factor parameters\n",
    "- Use only independent, strong factors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}